"""
çŸ­å‰§å‰§æœ¬ç”Ÿæˆå™¨ - Streamlit Demo
è¿è¡Œæ–¹å¼: streamlit run app.py
"""

import streamlit as st
import time
import os

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="çŸ­å‰§å‰§æœ¬ç”Ÿæˆå™¨",
    page_icon="ğŸ“",
    layout="wide"
)

# åˆå§‹åŒ– session state
if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "api_provider" not in st.session_state:
    st.session_state.api_provider = "claude"

# æ ‡é¢˜
st.title("ğŸ“ çŸ­å‰§å‰§æœ¬ç”Ÿæˆå™¨")
st.markdown("è¾“å…¥å°è¯´ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸“ä¸šæ ¼å¼çš„çŸ­å‰§å‰§æœ¬")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®å‚æ•°")

    st.markdown("""
    **ä¼˜åŒ–çº§åˆ«è¯´æ˜**
    - åŸºç¡€ä¼˜åŒ–ï¼šä»…æ ¼å¼åŒ–ï¼ˆåœºæ¬¡ç¼–å·ã€åœºæ™¯æ ‡æ³¨ï¼‰
    - æ ‡å‡†ä¼˜åŒ–ï¼šæ ¼å¼åŒ– + è¡¨æ¼”æç¤º + ç‰¹å†™é•œå¤´
    - æ·±åº¦ä¼˜åŒ–ï¼šå…¨éƒ¨ + é…è§’è®°å¿†ç‚¹ + å°è¯ä¼˜åŒ–
    """)

    st.divider()

    title = st.text_input("å‰§æœ¬æ ‡é¢˜", value="çŸ­å‰§å‰§æœ¬", help="é»˜è®¤ä¸º'çŸ­å‰§å‰§æœ¬'")

    genre = st.selectbox(
        "é¢˜æç±»å‹",
        ["éƒ½å¸‚", "å¤è£…å®…æ–—", "ä»™ä¾ ç„å¹»", "ç”œå® ", "é‡ç”Ÿå¤ä»‡", "ç©¿è¶Š", "è±ªé—¨", "å…¶ä»–"],
        help="é€‰æ‹©å‰§æœ¬çš„é¢˜æç±»å‹"
    )

    episodes = st.slider("æ€»é›†æ•°", min_value=3, max_value=50, value=30, help="å»ºè®® 20-40 é›†")

    opt_level = st.selectbox(
        "ä¼˜åŒ–çº§åˆ«",
        ["deep", "standard", "basic"],
        format_func=lambda x: {
            "standard": "æ ‡å‡†ä¼˜åŒ–",
            "basic": "åŸºç¡€ä¼˜åŒ–",
            "deep": "æ·±åº¦ä¼˜åŒ–"
        }[x],
        help="åŸºç¡€ä¼˜åŒ–ï¼šä»…æ ¼å¼åŒ–ï¼›æ ‡å‡†ä¼˜åŒ–ï¼šæ ¼å¼+è¡¨æ¼”æç¤ºï¼›æ·±åº¦ä¼˜åŒ–ï¼šæ ¼å¼+è¡¨æ¼”æç¤º+é…è§’è®°å¿†ç‚¹"
    )

    st.divider()

    # API é…ç½®
    st.header("ğŸ”‘ API é…ç½®")

    api_provider = st.selectbox(
        "API æä¾›å•†",
        ["claude", "openai", "gemini", "deepseek", "qwen", "ernie", "chatglm", "kimi"],
        format_func=lambda x: {
            "claude": "Claude (Anthropic)",
            "openai": "OpenAI GPT-4",
            "gemini": "Google Gemini",
            "deepseek": "DeepSeek",
            "qwen": "é˜¿é‡Œé€šä¹‰åƒé—®",
            "ernie": "ç™¾åº¦æ–‡å¿ƒä¸€è¨€",
            "chatglm": "æ™ºè°± ChatGLM",
            "kimi": "Kimi (Moonshot)"
        }[x],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„ AI API"
    )

    api_key = st.text_input(
        "API Key",
        type="password",
        help="è¯·è¾“å…¥ä½ çš„ API Keyï¼ˆä¸ä¼šä¿å­˜ï¼Œä»…æœ¬æ¬¡ä½¿ç”¨ï¼‰"
    )

    if api_key:
        st.session_state.api_key = api_key
        st.session_state.api_provider = api_provider
        st.success("âœ… API Key å·²é…ç½®")

    st.divider()

    st.markdown("""
    **å­—æ•°å»ºè®®**
    - < 5,000å­—ï¼š3-5é›†
    - 5,000-15,000å­—ï¼š10-15é›†
    - 15,000-30,000å­—ï¼š20-30é›†
    - > 30,000å­—ï¼šå»ºè®®åˆ†æ‰¹
    """)

    st.divider()

    st.markdown("""
    **æç¤º**
    - éœ€è¦è‡ªå¤‡ API Key
    - Claude: https://console.anthropic.com
    - OpenAI: https://platform.openai.com/api-keys
    - Gemini: https://aistudio.google.com
    - DeepSeek: https://platform.deepseek.com
    - é€šä¹‰åƒé—®: https://dashscope.console.aliyun.com
    - æ–‡å¿ƒä¸€è¨€: https://console.bce.baidu.com
    - ChatGLM: https://open.bigmodel.cn
    - Kimi: https://platform.moonshot.cn
    """)

# ä¸»å†…å®¹åŒº
novel_input = st.text_area(
    "å°è¯´åŸæ–‡",
    height=300,
    placeholder="è¯·ç²˜è´´å°è¯´åŸæ–‡...",
    help="å»ºè®®å­—æ•°ï¼š5,000 - 30,000 å­—"
)

# ç”ŸæˆæŒ‰é’®
if st.button("ğŸ¬ ç”Ÿæˆå‰§æœ¬", type="primary", disabled=not novel_input):
    if not novel_input.strip():
        st.error("è¯·è¾“å…¥å°è¯´å†…å®¹")
    elif not st.session_state.api_key:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§é…ç½® API Key")
    else:
        with st.spinner("æ­£åœ¨ç”Ÿæˆå‰§æœ¬ï¼Œè¯·ç¨å€™ï¼ˆå¯èƒ½éœ€è¦ 30-60 ç§’ï¼‰..."):
            try:
                # è°ƒç”¨ AI æ¨¡å‹
                script_content = call_ai_model(
                    novel=novel_input,
                    title=title,
                    genre=genre,
                    episodes=episodes,
                    opt_level=opt_level,
                    api_key=st.session_state.api_key,
                    provider=st.session_state.api_provider
                )

                # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
                report = {
                    "æ ¼å¼é—®é¢˜ä¿®å¤": 3,
                    "è¡¨æ¼”æç¤ºè¡¥å……": 5,
                    "ç‰¹å†™é•œå¤´è¡¥å……": 2,
                    "é…è§’è®°å¿†ç‚¹è¡¥å……": 1
                }

                st.success("ç”Ÿæˆå®Œæˆï¼")

            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
                script_content = None

        if script_content:
            # æ˜¾ç¤ºä¼˜åŒ–æŠ¥å‘Š
            with st.expander("ğŸ“Š ä¼˜åŒ–æŠ¥å‘Š", expanded=True):
                cols = st.columns(4)
                for i, (item, count) in enumerate(report.items()):
                    cols[i % 4].metric(item, count)

            # æ˜¾ç¤ºå‰§æœ¬
            st.subheader("ğŸ“„ ç”Ÿæˆçš„å‰§æœ¬")

            # å‰§æœ¬é¢„è§ˆï¼ˆå¯æŠ˜å ï¼‰
            with st.expander("é¢„è§ˆå®Œæ•´å‰§æœ¬", expanded=True):
                st.markdown(script_content)

            # ä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å‰§æœ¬",
                data=script_content,
                file_name=f"{title}.md",
                mime="text/markdown"
            )

# åº•éƒ¨è¯´æ˜
st.divider()
st.markdown("""
---
**æ ¼å¼è¯´æ˜**

| æ ‡è®° | ç”¨é€” |
|------|------|
| 1-1, 1-2... | åœºæ¬¡ç¼–å· |
| æ—¥/å¤œ + å†…/å¤– | åœºæ™¯æ ‡æ³¨ |
| ã€ç‰¹å†™ã€‘ | å…³é”®æƒ…æ„Ÿé•œå¤´ |
| ã€â˜…è¡¨æ¼”æç¤ºã€‘ | è¡¨æ¼”è¦ç‚¹ |
| ã€ç”»å¤–éŸ³Â·äººç‰©åã€‘ | å†…å¿ƒç‹¬ç™½ |
| ã€åˆ‡é•œã€‘ã€å­—å¹•ã€‘ | è½¬åœºæŠ€å·§ |
""")

# ==================== AI API è°ƒç”¨å‡½æ•° ====================

def call_ai_model(novel, title, genre, episodes, opt_level, api_key, provider):
    """
    è°ƒç”¨ AI æ¨¡å‹ç”Ÿæˆå‰§æœ¬

    Args:
        novel: å°è¯´åŸæ–‡
        title: å‰§æœ¬æ ‡é¢˜
        genre: é¢˜æç±»å‹
        episodes: æ€»é›†æ•°
        opt_level: ä¼˜åŒ–çº§åˆ«
        api_key: API Key
        provider: claude / openai

    Returns:
        ç”Ÿæˆçš„å‰§æœ¬å†…å®¹
    """
    # é¢˜æä¾§é‡ç‚¹
    genre_focus = {
        "éƒ½å¸‚": "èŒåœºã€ç”Ÿæ´»ã€ç°å®æƒ…æ„Ÿ",
        "å¤è£…å®…æ–—": "å¿ƒæœºç®—è®¡ã€èº«ä»½åœ°ä½ã€ä¸»ä»†å…³ç³»",
        "ä»™ä¾ ç„å¹»": "ä¿®ç‚¼å‡çº§ã€æ³•å®çµå™¨ã€é—¨æ´¾æ©æ€¨",
        "ç”œå® ": "æ„Ÿæƒ…äº’åŠ¨ã€èº«ä»½å·®è·ã€æµªæ¼«æ¡¥æ®µ",
        "é‡ç”Ÿå¤ä»‡": "ä¿¡æ¯å·®ã€é¢„çŸ¥æœªæ¥ã€æ”¹å˜å‘½è¿",
        "ç©¿è¶Š": "èº«ä»½é”™ä½ã€å¤ä»£ä¸ç°ä»£ç¢°æ’",
        "è±ªé—¨": "è´¢äº§äº‰å¤ºã€å®¶æ—æ©æ€¨ã€èº«ä»½å·®è·"
    }

    # ç”Ÿæˆæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ­å‰§ç¼–å‰§ï¼Œæ“…é•¿å°†å°è¯´æ”¹ç¼–æˆä¸“ä¸šæ ¼å¼çš„çŸ­å‰§å‰§æœ¬ã€‚"""

    user_prompt = f"""è¯·å°†ä»¥ä¸‹å°è¯´è½¬æ¢æˆä¸“ä¸šæ ¼å¼çš„çŸ­å‰§å‰§æœ¬ã€‚

=== åŸºç¡€é…ç½® ===
æ ‡é¢˜ï¼š{title}
é¢˜æï¼š{genre}
æ€»é›†æ•°ï¼š{episodes}

=== æ ¼å¼æ¨¡æ¿ ===
# çŸ­å‰§å‰§æœ¬ï¼š{title}

**é¢˜æï¼š** {genre}
**æ€»é›†æ•°ï¼š** {episodes}é›†

**æ•…äº‹æ¢—æ¦‚ï¼š** 1-2å¥è¯æ¦‚æ‹¬æ ¸å¿ƒå†²çª

**äººç‰©å°ä¼ ï¼š**

| è§’è‰² | å¹´é¾„ | èº«ä»½/èŒä¸š | æ€§æ ¼ç‰¹ç‚¹ | æ ¸å¿ƒèƒŒæ™¯ |
|------|------|-----------|---------|----------|
| ä¸»è§’ | xxå² | xxx | xxx | xxx |
| é…è§’1 | xxå² | xxx | xxx | xxx |

**è¡¨æ¼”è®°å¿†ç‚¹ï¼š**

| è§’è‰² | æ€§æ ¼æ ‡ç­¾ | å£å¤´ç¦… | æ ‡å¿—æ€§åŠ¨ä½œ |
|------|---------|--------|------------|
| ä¸»è§’ | xxx | xxx | xxx |
| é…è§’1 | xxx | xxx | xxx |

---

**ç¬¬1é›†ï¼šæ ‡é¢˜**
**æ ¸å¿ƒå‰§æƒ…ï¼š** ...

1-1   åœºæ™¯åç§°     æ—¥/å¤œ    å†…/å¤–
äººç‰©ï¼šxxx

â–² åœºæ™¯æè¿°
ã€ç‰¹å†™ã€‘å…³é”®é•œå¤´
äººç‰©ï¼ˆæƒ…ç»ªï¼‰ï¼šå°è¯
ã€â˜…è¡¨æ¼”æç¤ºã€‘

â–² åˆ‡é•œ

1-2   åœºæ™¯åç§°     æ—¥/å¤œ    å†…/å¤–
äººç‰©ï¼šxxx

...

=== æ ¼å¼è¦æ±‚ ===
1. åœºæ¬¡ç¼–å·ï¼š1-1, 1-2, 2-1...ï¼ˆè¿ç»­é€’å¢ï¼‰
2. åœºæ™¯æ ‡æ³¨ï¼šæ—¥/å¤œ + å†…/å¤–ï¼ˆå¿…å¡«ï¼‰
3. å…³é”®é•œå¤´ï¼šã€ç‰¹å†™ã€‘+ æè¿°
4. è¡¨æ¼”æç¤ºï¼šã€â˜…è¡¨æ¼”æç¤ºã€‘+ æƒ…ç»ª/åŠ¨ä½œ
5. è½¬åœºï¼šã€åˆ‡é•œã€‘ã€é»‘å±ã€‘ã€å­—å¹•ï¼šXå¹´åã€‘ã€é—ªå›ã€‘ã€è’™å¤ªå¥‡ã€‘
6. å†…å¿ƒç‹¬ç™½ï¼šã€ç”»å¤–éŸ³Â·äººç‰©åã€‘
7. é…è§’å¿…é¡»æœ‰å£å¤´ç¦…å’Œæ ‡å¿—æ€§åŠ¨ä½œ

=== é¢˜æä¾§é‡ç‚¹ ===
{genre}é¢˜æå…³æ³¨ï¼š{genre_focus.get(genre, 'æƒ…æ„Ÿçº è‘›')}

è¯·ç›´æ¥è¾“å‡ºå®Œæ•´å‰§æœ¬ã€‚

å°è¯´åŸæ–‡ï¼š
{novel}"""

    if provider == "claude":
        return call_claude_api(system_prompt, user_prompt, api_key)
    elif provider == "openai":
        return call_openai_api(system_prompt, user_prompt, api_key)
    elif provider == "gemini":
        return call_gemini_api(system_prompt, user_prompt, api_key)
    elif provider == "deepseek":
        return call_deepseek_api(system_prompt, user_prompt, api_key)
    elif provider == "qwen":
        return call_qwen_api(system_prompt, user_prompt, api_key)
    elif provider == "ernie":
        return call_ernie_api(system_prompt, user_prompt, api_key)
    elif provider == "chatglm":
        return call_chatglm_api(system_prompt, user_prompt, api_key)
    elif provider == "kimi":
        return call_kimi_api(system_prompt, user_prompt, api_key)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ API æä¾›å•†: {provider}")


def call_claude_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨ Claude API"""
    import anthropic

    client = anthropic.Anthropic(api_key=api_key)

    message = client.messages.create(
        model="sonnet-4-20250514",
        max_tokens=64000,
        system=system_prompt,
        messages=[
            {"role": "user", "content": user_prompt}
        ]
    )

    return message.content[0].text


def call_openai_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨ OpenAI API"""
    from openai import OpenAI

    client = OpenAI(api_key=api_key)

    response = client.chat.completions.create(
        model="gpt-4o",
        max_tokens=64000,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )

    return response.choices[0].message.content


# ==================== æ›´å¤š API è°ƒç”¨å‡½æ•° ====================

def call_gemini_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨ Google Gemini API"""
    import google.generativeai as genai

    genai.configure(api_key=api_key)

    model = genai.GenerativeModel(
        model_name="gemini-1.5-pro",
        system_instruction=system_prompt
    )

    response = model.generate_content(user_prompt)
    return response.text


def call_deepseek_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨ DeepSeek API"""
    import openai

    client = openai.OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
    )

    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content


def call_qwen_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨é˜¿é‡Œé€šä¹‰åƒé—® API"""
    import openai

    client = openai.OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    response = client.chat.completions.create(
        model="qwen-plus",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content


def call_ernie_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€ API"""
    import openai

    client = openai.OpenAI(
        api_key=api_key,
        base_url="https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat"
    )

    # éœ€è¦å…ˆè·å– access_tokenï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
    response = client.chat.completions.create(
        model="ernie-4.5-turbo-8k",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content


def call_chatglm_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨æ™ºè°± ChatGLM API"""
    import openai

    client = openai.OpenAI(
        api_key=api_key,
        base_url="https://open.bigmodel.cn/api/paas/v4"
    )

    response = client.chat.completions.create(
        model="glm-4-plus",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content


def call_kimi_api(system_prompt, user_prompt, api_key):
    """è°ƒç”¨ Kimi (Moonshot) API"""
    import openai

    client = openai.OpenAI(
        api_key=api_key,
        base_url="https://api.moonshot.cn/v1"
    )

    response = client.chat.completions.create(
        model="moonshot-v1-8k",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content


# ==================== æ¨¡æ‹Ÿå‡½æ•°ï¼ˆå¤‡ç”¨ï¼‰ ====================

def generate_mock_script(title, genre, episodes):
    """æ¨¡æ‹Ÿç”Ÿæˆè„šæœ¬ï¼ˆæ—  API Key æ—¶ä½¿ç”¨ï¼‰"""
    return f'''# çŸ­å‰§å‰§æœ¬ï¼š{title}

**é¢˜æï¼š** {genre}
**æ€»é›†æ•°ï¼š** {episodes}é›†

**æ•…äº‹æ¢—æ¦‚ï¼š** ä¸«é¬Ÿè‹æ¸…æ™è¢«é€¼æ›¿å°å§ä¸å§‘çˆ·åŒåºŠä¸‰å¹´ï¼Œæ±‚è§£æ”¾æ—¶è¢«è¿«ä¸ä¾¯åºœç—…å¼±å¤§å…¬å­æ²ˆæ™¯ç©ç»“é˜´äº²ã€‚

**äººç‰©å°ä¼ ï¼š**

| è§’è‰² | å¹´é¾„ | èº«ä»½/èŒä¸š | æ€§æ ¼ç‰¹ç‚¹ | æ ¸å¿ƒèƒŒæ™¯ |
|------|------|-----------|---------|----------|
| è‹æ¸…æ™ | 18å² | é™ªå«ä¸«é¬Ÿ | éšå¿åšéŸ§ | å®¶ç”Ÿå­ |
| æ²ˆæ™¯ç© | 27å² | ä¾¯åºœå«¡é•¿å­ | æ¸…å†·æ‰å­ | æ³¨å®šæ—©é€ |

**è¡¨æ¼”è®°å¿†ç‚¹ï¼š**

| è§’è‰² | æ€§æ ¼æ ‡ç­¾ | å£å¤´ç¦… | æ ‡å¿—æ€§åŠ¨ä½œ |
|------|---------|--------|------------|
| è‹æ¸…æ™ | éšå¿åšéŸ§ | "å¥´å©¢ä¸æ•¢" | ä½çœ‰é¡ºçœ¼ |

---

ï¼ˆå…±{episodes}é›†ï¼Œè¯·é…ç½® API Key ç”Ÿæˆå®Œæ•´å‰§æœ¬ï¼‰
'''
